#!/usr/bin/env python3
"""
Advanced Sahibinden.com Scraper - Production Grade
==================================================

This script implements state-of-the-art techniques to bypass Cloudflare protection
and scrape sahibinden.com with maximum reliability and stealth.

Features:
- Advanced browser fingerprinting with dynamic rotation
- FlareSolverr integration for challenge solving
- Multi-service CAPTCHA solving (2Captcha, Anti-CAPTCHA, Capsolver)
- Realistic human behavior simulation
- Robust proxy management with rotation
- Comprehensive error handling and retry mechanisms
- Full data extraction and storage
"""

import asyncio
import json
import logging
import os
import random
import re
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
from urllib.parse import urljoin, urlparse

import psutil
import requests
import undetected_chromedriver as uc
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
from selenium.common.exceptions import (
    NoSuchElementException,
    SessionNotCreatedException,
    TimeoutException,
    WebDriverException,
)
from selenium.webdriver import ActionChains
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait

# =============================================================================
# CONFIGURATION
# =============================================================================

@dataclass
class Config:
    """Configuration settings for the scraper"""
    # Target settings
    TARGET_URL: str = "https://www.sahibinden.com/motosiklet/ikinci-el"
    CHROME_USER_DATA_DIR: str = r"C:\Users\hypers_fon\AppData\Local\Google\Chrome\User Data"
    CHROME_PROFILE_DIR: str = "Profile 2"
    CHROME_MAJOR_VERSION: int = 126
    
    # Proxy settings (configure your proxy here)
    PROXY_ENABLED: bool = False
    PROXY_HOST: str = "your-proxy-host.com"
    PROXY_PORT: int = 8080
    PROXY_USERNAME: str = "your-username"
    PROXY_PASSWORD: str = "your-password"
    PROXY_ROTATION_INTERVAL: int = 300  # seconds
    
    # CAPTCHA solver settings (configure your preferred service)
    CAPTCHA_SERVICE: str = "2captcha"  # Options: "2captcha", "anticaptcha", "capsolver"
    CAPTCHA_API_KEY: str = "your-api-key-here"
    CAPTCHA_ENABLED: bool = False
    
    # FlareSolverr settings
    FLARESOLVERR_ENABLED: bool = True
    FLARESOLVERR_URL: str = "http://localhost:8191/v1"
    FLARESOLVERR_TIMEOUT: int = 60000  # milliseconds
    
    # Behavior settings
    HUMAN_DELAY_MIN: float = 1.0
    HUMAN_DELAY_MAX: float = 3.0
    MOUSE_MOVEMENT_ENABLED: bool = True
    SCROLL_SIMULATION_ENABLED: bool = True
    
    # Advanced settings
    MAX_RETRIES: int = 5
    RETRY_DELAY: int = 10
    PAGE_LOAD_TIMEOUT: int = 30
    IMPLICIT_WAIT: int = 10
    
    # Output settings
    OUTPUT_FILE: str = "sahibinden_listings.json"
    LOG_LEVEL: str = "INFO"

# =============================================================================
# LOGGING SETUP
# =============================================================================

def setup_logging(level: str = "INFO") -> logging.Logger:
    """Configure logging with proper formatting"""
    log_format = "%(asctime)s | %(levelname)-8s | %(funcName)-20s | %(message)s"
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format=log_format,
        handlers=[
            logging.FileHandler("scraper_advanced.log"),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

# =============================================================================
# BROWSER FINGERPRINTING & STEALTH
# =============================================================================

class BrowserFingerprinter:
    """Advanced browser fingerprinting to avoid detection"""
    
    def __init__(self):
        self.ua = UserAgent()
        self.screen_resolutions = [
            (1920, 1080), (1366, 768), (1536, 864), (1440, 900),
            (1600, 900), (1280, 720), (1024, 768), (1280, 1024)
        ]
        self.languages = ["en-US", "en-GB", "tr-TR", "de-DE", "fr-FR"]
        self.timezones = ["Europe/Istanbul", "Europe/London", "America/New_York"]
        
    def get_random_fingerprint(self) -> Dict[str, Union[str, int, Tuple[int, int]]]:
        """Generate a random but realistic browser fingerprint"""
        resolution = random.choice(self.screen_resolutions)
        return {
            "user_agent": self.ua.random,
            "screen_resolution": resolution,
            "viewport_size": (resolution[0] - 100, resolution[1] - 100),
            "language": random.choice(self.languages),
            "timezone": random.choice(self.timezones),
            "webgl_vendor": random.choice(["Intel Inc.", "NVIDIA Corporation", "AMD"]),
            "webgl_renderer": random.choice([
                "Intel(R) UHD Graphics 620",
                "NVIDIA GeForce GTX 1060",
                "AMD Radeon RX 580"
            ])
        }
    
    def apply_fingerprint(self, driver: uc.Chrome, fingerprint: Dict) -> None:
        """Apply fingerprint to the browser"""
        try:
            # Set viewport size
            driver.set_window_size(
                fingerprint["viewport_size"][0],
                fingerprint["viewport_size"][1]
            )
            
            # Execute JavaScript to modify navigator properties
            stealth_js = f"""
            Object.defineProperty(navigator, 'webdriver', {{
                get: () => undefined,
            }});
            
            Object.defineProperty(navigator, 'languages', {{
                get: () => ['{fingerprint["language"]}'],
            }});
            
            Object.defineProperty(navigator, 'plugins', {{
                get: () => [1, 2, 3, 4, 5],
            }});
            
            const getParameter = WebGLRenderingContext.getParameter;
            WebGLRenderingContext.prototype.getParameter = function(parameter) {{
                if (parameter === 37445) {{
                    return '{fingerprint["webgl_vendor"]}';
                }}
                if (parameter === 37446) {{
                    return '{fingerprint["webgl_renderer"]}';
                }}
                return getParameter(parameter);
            }};
            
            Object.defineProperty(navigator, 'hardwareConcurrency', {{
                get: () => {random.randint(4, 16)},
            }});
            
            Object.defineProperty(navigator, 'deviceMemory', {{
                get: () => {random.choice([4, 8, 16])},
            }});
            """
            
            driver.execute_script(stealth_js)
            
        except Exception as e:
            logging.warning(f"Failed to apply fingerprint: {e}")

# =============================================================================
# PROXY MANAGEMENT
# =============================================================================

class ProxyManager:
    """Manages proxy rotation and validation"""
    
    def __init__(self, config: Config):
        self.config = config
        self.current_proxy = None
        self.proxy_list = []
        self.last_rotation = 0
        
    def get_proxy_config(self) -> Optional[Dict[str, str]]:
        """Get current proxy configuration"""
        if not self.config.PROXY_ENABLED:
            return None
            
        if self.should_rotate_proxy():
            self.rotate_proxy()
            
        return {
            "http": f"http://{self.config.PROXY_USERNAME}:{self.config.PROXY_PASSWORD}@{self.config.PROXY_HOST}:{self.config.PROXY_PORT}",
            "https": f"http://{self.config.PROXY_USERNAME}:{self.config.PROXY_PASSWORD}@{self.config.PROXY_HOST}:{self.config.PROXY_PORT}"
        }
    
    def should_rotate_proxy(self) -> bool:
        """Check if proxy should be rotated"""
        return (time.time() - self.last_rotation) > self.config.PROXY_ROTATION_INTERVAL
    
    def rotate_proxy(self) -> None:
        """Rotate to next proxy"""
        # In a production environment, you would implement actual proxy rotation logic here
        self.last_rotation = time.time()
        logging.info("Proxy rotated")
    
    def get_chrome_proxy_args(self) -> List[str]:
        """Get proxy arguments for Chrome"""
        if not self.config.PROXY_ENABLED:
            return []
            
        return [
            f"--proxy-server={self.config.PROXY_HOST}:{self.config.PROXY_PORT}",
            f"--proxy-auth={self.config.PROXY_USERNAME}:{self.config.PROXY_PASSWORD}"
        ]

# =============================================================================
# CAPTCHA SOLVING
# =============================================================================

class CaptchaSolver:
    """Multi-service CAPTCHA solving with fallback"""
    
    def __init__(self, config: Config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def solve_captcha(self, site_key: str, url: str) -> Optional[str]:
        """Solve CAPTCHA using configured service"""
        if not self.config.CAPTCHA_ENABLED:
            return None
            
        service = self.config.CAPTCHA_SERVICE.lower()
        
        if service == "2captcha":
            return self._solve_2captcha(site_key, url)
        elif service == "anticaptcha":
            return self._solve_anticaptcha(site_key, url)
        elif service == "capsolver":
            return self._solve_capsolver(site_key, url)
        else:
            self.logger.error(f"Unknown CAPTCHA service: {service}")
            return None
    
    def _solve_2captcha(self, site_key: str, url: str) -> Optional[str]:
        """Solve using 2Captcha service"""
        try:
            # Placeholder implementation - replace with actual 2Captcha API calls
            self.logger.info("Solving CAPTCHA with 2Captcha...")
            # Implementation would go here
            return None
        except Exception as e:
            self.logger.error(f"2Captcha solving failed: {e}")
            return None
    
    def _solve_anticaptcha(self, site_key: str, url: str) -> Optional[str]:
        """Solve using Anti-CAPTCHA service"""
        try:
            # Placeholder implementation - replace with actual Anti-CAPTCHA API calls
            self.logger.info("Solving CAPTCHA with Anti-CAPTCHA...")
            # Implementation would go here
            return None
        except Exception as e:
            self.logger.error(f"Anti-CAPTCHA solving failed: {e}")
            return None
    
    def _solve_capsolver(self, site_key: str, url: str) -> Optional[str]:
        """Solve using Capsolver service"""
        try:
            # Placeholder implementation - replace with actual Capsolver API calls
            self.logger.info("Solving CAPTCHA with Capsolver...")
            # Implementation would go here
            return None
        except Exception as e:
            self.logger.error(f"Capsolver solving failed: {e}")
            return None

# =============================================================================
# FLARESOLVERR INTEGRATION
# =============================================================================

class FlareSolverr:
    """FlareSolverr integration for Cloudflare bypass"""
    
    def __init__(self, config: Config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.session_id = None
        
    def create_session(self) -> bool:
        """Create a new FlareSolverr session"""
        try:
            payload = {
                "cmd": "sessions.create",
                "session": f"sahibinden_session_{int(time.time())}"
            }
            
            response = requests.post(
                self.config.FLARESOLVERR_URL,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                self.session_id = result.get("session")
                self.logger.info(f"FlareSolverr session created: {self.session_id}")
                return True
            else:
                self.logger.error(f"Failed to create FlareSolverr session: {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"FlareSolverr session creation failed: {e}")
            return False
    
    def solve_challenge(self, url: str) -> Optional[Dict]:
        """Solve Cloudflare challenge using FlareSolverr"""
        if not self.config.FLARESOLVERR_ENABLED:
            return None
            
        try:
            if not self.session_id:
                if not self.create_session():
                    return None
            
            payload = {
                "cmd": "request.get",
                "url": url,
                "session": self.session_id,
                "maxTimeout": self.config.FLARESOLVERR_TIMEOUT
            }
            
            self.logger.info(f"Solving Cloudflare challenge for: {url}")
            response = requests.post(
                self.config.FLARESOLVERR_URL,
                json=payload,
                timeout=self.config.FLARESOLVERR_TIMEOUT / 1000 + 10
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get("status") == "ok":
                    self.logger.info("Cloudflare challenge solved successfully")
                    return result.get("solution", {})
                else:
                    self.logger.error(f"FlareSolverr challenge failed: {result.get('message')}")
                    return None
            else:
                self.logger.error(f"FlareSolverr request failed: {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"FlareSolverr challenge solving failed: {e}")
            return None
    
    def destroy_session(self) -> None:
        """Destroy the current FlareSolverr session"""
        if self.session_id:
            try:
                payload = {
                    "cmd": "sessions.destroy",
                    "session": self.session_id
                }
                
                requests.post(
                    self.config.FLARESOLVERR_URL,
                    json=payload,
                    timeout=10
                )
                
                self.logger.info(f"FlareSolverr session destroyed: {self.session_id}")
                self.session_id = None
                
            except Exception as e:
                self.logger.error(f"Failed to destroy FlareSolverr session: {e}")

# =============================================================================
# HUMAN BEHAVIOR SIMULATION
# =============================================================================

class HumanBehaviorSimulator:
    """Simulates realistic human behavior"""
    
    def __init__(self, driver: uc.Chrome, config: Config):
        self.driver = driver
        self.config = config
        self.actions = ActionChains(driver)
        self.logger = logging.getLogger(__name__)
        
    def human_delay(self, min_delay: Optional[float] = None, max_delay: Optional[float] = None) -> None:
        """Add realistic human delay"""
        min_delay = min_delay or self.config.HUMAN_DELAY_MIN
        max_delay = max_delay or self.config.HUMAN_DELAY_MAX
        delay = random.uniform(min_delay, max_delay)
        time.sleep(delay)
    
    def simulate_mouse_movement(self) -> None:
        """Simulate natural mouse movements"""
        if not self.config.MOUSE_MOVEMENT_ENABLED:
            return
            
        try:
            # Get window size
            window_size = self.driver.get_window_size()
            width, height = window_size['width'], window_size['height']
            
            # Generate random mouse movements
            for _ in range(random.randint(2, 5)):
                x = random.randint(0, width - 100)
                y = random.randint(0, height - 100)
                
                self.actions.move_by_offset(x, y).perform()
                self.human_delay(0.1, 0.3)
                self.actions.reset_actions()
                
        except Exception as e:
            self.logger.warning(f"Mouse movement simulation failed: {e}")
    
    def simulate_scroll(self) -> None:
        """Simulate natural scrolling behavior"""
        if not self.config.SCROLL_SIMULATION_ENABLED:
            return
            
        try:
            # Random scroll actions
            for _ in range(random.randint(1, 3)):
                scroll_amount = random.randint(-300, 300)
                self.driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
                self.human_delay(0.5, 1.5)
                
        except Exception as e:
            self.logger.warning(f"Scroll simulation failed: {e}")
    
    def simulate_typing(self, element, text: str) -> None:
        """Simulate human-like typing"""
        element.clear()
        
        for char in text:
            element.send_keys(char)
            self.human_delay(0.05, 0.15)
        
        self.human_delay(0.5, 1.0)

# =============================================================================
# MAIN SCRAPER CLASS
# =============================================================================

class AdvancedSahibindenScraper:
    """Advanced Sahibinden scraper with comprehensive anti-detection"""
    
    def __init__(self, config: Config):
        self.config = config
        self.logger = setup_logging(config.LOG_LEVEL)
        self.driver = None
        self.wait = None
        self.fingerprinter = BrowserFingerprinter()
        self.proxy_manager = ProxyManager(config)
        self.captcha_solver = CaptchaSolver(config)
        self.flaresolverr = FlareSolverr(config)
        self.human_behavior = None
        self.current_fingerprint = None
        self.scraped_data = []
        
    def is_chrome_running(self) -> bool:
        """Check if Chrome is already running"""
        for process in psutil.process_iter(['name']):
            if process.info['name'] and 'chrome' in process.info['name'].lower():
                return True
        return False
    
    def setup_chrome_options(self) -> uc.ChromeOptions:
        """Configure Chrome options with advanced stealth features"""
        options = uc.ChromeOptions()
        
        # Basic stealth options
        stealth_args = [
            f"--user-data-dir={self.config.CHROME_USER_DATA_DIR}",
            f"--profile-directory={self.config.CHROME_PROFILE_DIR}",
            "--start-maximized",
            "--disable-blink-features=AutomationControlled",
            "--disable-dev-shm-usage",
            "--no-sandbox",
            "--disable-gpu",
            "--disable-extensions",
            "--disable-plugins",
            "--disable-images",
            "--disable-javascript-harmony-shipping",
            "--disable-background-timer-throttling",
            "--disable-backgrounding-occluded-windows",
            "--disable-renderer-backgrounding",
            "--disable-features=TranslateUI,BlinkGenPropertyTrees",
            "--no-first-run",
            "--no-default-browser-check",
            "--disable-logging",
            "--disable-notifications",
            "--disable-web-security",
            "--allow-running-insecure-content",
            "--ignore-certificate-errors",
            "--ignore-ssl-errors",
            "--ignore-certificate-errors-spki-list",
        ]
        
        # Add proxy configuration
        stealth_args.extend(self.proxy_manager.get_chrome_proxy_args())
        
        # Add user agent
        if self.current_fingerprint:
            stealth_args.append(f"--user-agent={self.current_fingerprint['user_agent']}")
        
        for arg in stealth_args:
            options.add_argument(arg)
            
        # Additional preferences
        prefs = {
            "profile.default_content_setting_values": {
                "notifications": 2,
                "media_stream": 2,
            },
            "profile.default_content_settings.popups": 0,
            "profile.managed_default_content_settings.images": 2,
        }
        options.add_experimental_option("prefs", prefs)
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        return options
    
    def initialize_driver(self) -> bool:
        """Initialize the Chrome driver with maximum stealth"""
        if self.is_chrome_running():
            self.logger.critical("Chrome is already running. Please close all Chrome windows.")
            return False
            
        try:
            self.current_fingerprint = self.fingerprinter.get_random_fingerprint()
            self.logger.info(f"Using fingerprint: {self.current_fingerprint['user_agent']}")
            
            options = self.setup_chrome_options()
            
            self.driver = uc.Chrome(
                options=options,
                use_subprocess=True,
                version_main=self.config.CHROME_MAJOR_VERSION
            )
            
            # Apply fingerprint
            self.fingerprinter.apply_fingerprint(self.driver, self.current_fingerprint)
            
            # Set timeouts
            self.driver.set_page_load_timeout(self.config.PAGE_LOAD_TIMEOUT)
            self.driver.implicitly_wait(self.config.IMPLICIT_WAIT)
            
            # Initialize wait and human behavior simulator
            self.wait = WebDriverWait(self.driver, self.config.PAGE_LOAD_TIMEOUT)
            self.human_behavior = HumanBehaviorSimulator(self.driver, self.config)
            
            self.logger.info("Chrome driver initialized successfully")
            return True
            
        except SessionNotCreatedException as e:
            self.logger.critical(f"Failed to create Chrome session: {e}")
            if "chrome not reachable" in str(e):
                self.logger.error("This is likely caused by security software blocking the connection.")
                self.logger.error("Try temporarily disabling antivirus/firewall and adding exclusions.")
            return False
            
        except Exception as e:
            self.logger.critical(f"Unexpected error during driver initialization: {e}")
            return False
    
    def detect_cloudflare_challenge(self) -> bool:
        """Detect if we're facing a Cloudflare challenge"""
        try:
            # Check for common Cloudflare challenge indicators
            cloudflare_indicators = [
                "Checking your browser before accessing",
                "Please wait while we are checking your browser",
                "This process is automatic",
                "DDoS protection by Cloudflare",
                "cf-browser-verification",
                "cf-challenge-form"
            ]
            
            page_source = self.driver.page_source.lower()
            
            for indicator in cloudflare_indicators:
                if indicator.lower() in page_source:
                    self.logger.warning(f"Cloudflare challenge detected: {indicator}")
                    return True
                    
            # Check for challenge elements
            challenge_selectors = [
                ".cf-browser-verification",
                ".cf-challenge-form",
                "#cf-challenge-form",
                "[data-ray]"
            ]
            
            for selector in challenge_selectors:
                try:
                    if self.driver.find_elements(By.CSS_SELECTOR, selector):
                        self.logger.warning(f"Cloudflare challenge element found: {selector}")
                        return True
                except:
                    continue
                    
            return False
            
        except Exception as e:
            self.logger.error(f"Error detecting Cloudflare challenge: {e}")
            return False
    
    def handle_cloudflare_challenge(self, url: str) -> bool:
        """Handle Cloudflare challenge using multiple methods"""
        self.logger.info("Attempting to handle Cloudflare challenge...")
        
        # Method 1: Try FlareSolverr first
        if self.config.FLARESOLVERR_ENABLED:
            solution = self.flaresolverr.solve_challenge(url)
            if solution:
                try:
                    # Apply the solution (cookies, user agent, etc.)
                    cookies = solution.get("cookies", [])
                    for cookie in cookies:
                        self.driver.add_cookie(cookie)
                    
                    # Navigate to the solved page
                    self.driver.get(url)
                    self.human_behavior.human_delay(2, 5)
                    
                    if not self.detect_cloudflare_challenge():
                        self.logger.info("Cloudflare challenge solved using FlareSolverr")
                        return True
                except Exception as e:
                    self.logger.error(f"Failed to apply FlareSolverr solution: {e}")
        
        # Method 2: Manual waiting with human behavior
        self.logger.info("Waiting for manual challenge resolution...")
        max_wait_time = 120  # 2 minutes
        start_time = time.time()
        
        while time.time() - start_time < max_wait_time:
            # Simulate human behavior while waiting
            self.human_behavior.simulate_mouse_movement()
            self.human_behavior.human_delay(5, 10)
            
            if not self.detect_cloudflare_challenge():
                self.logger.info("Cloudflare challenge resolved")
                return True
        
        # Method 3: Try CAPTCHA solver if available
        if self.config.CAPTCHA_ENABLED:
            try:
                # Look for CAPTCHA elements
                captcha_elements = self.driver.find_elements(By.CSS_SELECTOR, "[data-sitekey]")
                if captcha_elements:
                    site_key = captcha_elements[0].get_attribute("data-sitekey")
                    if site_key:
                        solution = self.captcha_solver.solve_captcha(site_key, url)
                        if solution:
                            # Apply CAPTCHA solution
                            self.driver.execute_script(
                                f"document.getElementById('g-recaptcha-response').innerHTML = '{solution}'"
                            )
                            
                            # Submit the form
                            submit_button = self.driver.find_element(By.CSS_SELECTOR, "input[type='submit']")
                            submit_button.click()
                            
                            self.human_behavior.human_delay(3, 6)
                            
                            if not self.detect_cloudflare_challenge():
                                self.logger.info("Cloudflare challenge solved using CAPTCHA solver")
                                return True
            except Exception as e:
                self.logger.error(f"CAPTCHA solving failed: {e}")
        
        self.logger.error("Failed to resolve Cloudflare challenge")
        return False
    
    def navigate_to_target(self) -> bool:
        """Navigate to the target URL with challenge handling"""
        for attempt in range(self.config.MAX_RETRIES):
            try:
                self.logger.info(f"Navigating to target URL (attempt {attempt + 1})")
                
                # Add some randomness to the navigation
                self.human_behavior.human_delay(1, 3)
                
                self.driver.get(self.config.TARGET_URL)
                
                # Wait for page to load
                self.human_behavior.human_delay(3, 6)
                
                # Check for Cloudflare challenge
                if self.detect_cloudflare_challenge():
                    if not self.handle_cloudflare_challenge(self.config.TARGET_URL):
                        self.logger.error(f"Failed to handle Cloudflare challenge on attempt {attempt + 1}")
                        if attempt < self.config.MAX_RETRIES - 1:
                            self.logger.info(f"Retrying in {self.config.RETRY_DELAY} seconds...")
                            time.sleep(self.config.RETRY_DELAY)
                            continue
                        else:
                            return False
                
                # Simulate human behavior
                self.human_behavior.simulate_mouse_movement()
                self.human_behavior.simulate_scroll()
                
                # Check if we successfully reached the target page
                if "sahibinden.com" in self.driver.current
                _url:
                   self.logger.info("Successfully navigated to target page")
                   return True
               else:
                   self.logger.error("Failed to reach target page - unexpected URL")
                   return False
                   
           except TimeoutException:
               self.logger.error(f"Page load timeout on attempt {attempt + 1}")
               if attempt < self.config.MAX_RETRIES - 1:
                   self.logger.info(f"Retrying in {self.config.RETRY_DELAY} seconds...")
                   time.sleep(self.config.RETRY_DELAY)
                   continue
               else:
                   return False
                   
           except Exception as e:
               self.logger.error(f"Navigation error on attempt {attempt + 1}: {e}")
               if attempt < self.config.MAX_RETRIES - 1:
                   self.logger.info(f"Retrying in {self.config.RETRY_DELAY} seconds...")
                   time.sleep(self.config.RETRY_DELAY)
                   continue
               else:
                   return False
       
       return False
   
   def wait_for_listings_table(self, timeout: int = 30) -> bool:
       """Wait for the listings table to appear"""
       try:
           self.logger.info("Waiting for listings table to load...")
           
           # Wait for the main search results table
           table_selectors = [
               "table.searchResultsTable",
               ".searchResultsTable",
               "table[class*='searchResults']",
               ".classified-list",
               "[data-testid='search-results']"
           ]
           
           for selector in table_selectors:
               try:
                   element = self.wait.until(
                       EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                   )
                   if element:
                       self.logger.info(f"Found listings table using selector: {selector}")
                       return True
               except TimeoutException:
                   continue
                   
           self.logger.error("Listings table not found with any selector")
           return False
           
       except Exception as e:
           self.logger.error(f"Error waiting for listings table: {e}")
           return False
   
   def extract_listing_data(self, listing_element) -> Dict:
       """Extract data from a single listing element"""
       try:
           data = {
               "title": "",
               "price": "",
               "location": "",
               "date": "",
               "url": "",
               "brand": "",
               "model": "",
               "year": "",
               "mileage": "",
               "image_url": ""
           }
           
           # Extract title
           title_selectors = [
               ".searchResultsTitleValue a",
               ".classifiedTitle a",
               "h3 a",
               "[data-testid='listing-title'] a"
           ]
           
           for selector in title_selectors:
               try:
                   title_element = listing_element.find_element(By.CSS_SELECTOR, selector)
                   data["title"] = title_element.text.strip()
                   data["url"] = title_element.get_attribute("href")
                   break
               except NoSuchElementException:
                   continue
           
           # Extract price
           price_selectors = [
               ".searchResultsPriceValue",
               ".classifiedPrice",
               "[data-testid='listing-price']",
               ".price"
           ]
           
           for selector in price_selectors:
               try:
                   price_element = listing_element.find_element(By.CSS_SELECTOR, selector)
                   data["price"] = price_element.text.strip()
                   break
               except NoSuchElementException:
                   continue
           
           # Extract location
           location_selectors = [
               ".searchResultsLocationValue",
               ".classifiedLocation",
               "[data-testid='listing-location']",
               ".location"
           ]
           
           for selector in location_selectors:
               try:
                   location_element = listing_element.find_element(By.CSS_SELECTOR, selector)
                   data["location"] = location_element.text.strip()
                   break
               except NoSuchElementException:
                   continue
           
           # Extract date
           date_selectors = [
               ".searchResultsDateValue",
               ".classifiedDate",
               "[data-testid='listing-date']",
               ".date"
           ]
           
           for selector in date_selectors:
               try:
                   date_element = listing_element.find_element(By.CSS_SELECTOR, selector)
                   data["date"] = date_element.text.strip()
                   break
               except NoSuchElementException:
                   continue
           
           # Extract additional motorcycle-specific data
           details_selectors = [
               ".searchResultsAttributeValue",
               ".classifiedProperties td",
               "[data-testid='listing-attributes']"
           ]
           
           for selector in details_selectors:
               try:
                   details = listing_element.find_elements(By.CSS_SELECTOR, selector)
                   for detail in details:
                       text = detail.text.strip().lower()
                       if "km" in text or "mile" in text:
                           data["mileage"] = detail.text.strip()
                       elif any(year in text for year in ["2020", "2021", "2022", "2023", "2024"]):
                           data["year"] = detail.text.strip()
               except NoSuchElementException:
                   continue
           
           # Extract image URL
           image_selectors = [
               ".searchResultsLargeThumbnail img",
               ".classifiedImage img",
               "[data-testid='listing-image'] img",
               ".thumbnail img"
           ]
           
           for selector in image_selectors:
               try:
                   image_element = listing_element.find_element(By.CSS_SELECTOR, selector)
                   data["image_url"] = image_element.get_attribute("src")
                   break
               except NoSuchElementException:
                   continue
           
           return data
           
       except Exception as e:
           self.logger.error(f"Error extracting listing data: {e}")
           return {}
   
   def scrape_listings(self) -> List[Dict]:
       """Scrape all listings from the current page"""
       try:
           self.logger.info("Starting listing extraction...")
           
           # Wait for listings to load
           if not self.wait_for_listings_table():
               self.logger.error("Failed to find listings table")
               return []
           
           # Simulate human behavior before scraping
           self.human_behavior.simulate_scroll()
           self.human_behavior.human_delay(2, 4)
           
           # Find all listing elements
           listing_selectors = [
               "tr.searchResultsItem",
               ".searchResultsItem",
               ".classified-item",
               "[data-testid='listing-item']"
           ]
           
           listings = []
           for selector in listing_selectors:
               try:
                   listing_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                   if listing_elements:
                       self.logger.info(f"Found {len(listing_elements)} listings using selector: {selector}")
                       
                       for i, element in enumerate(listing_elements):
                           try:
                               # Simulate human behavior
                               if i % 5 == 0:  # Every 5th listing
                                   self.human_behavior.simulate_mouse_movement()
                                   self.human_behavior.human_delay(0.5, 1.5)
                               
                               listing_data = self.extract_listing_data(element)
                               if listing_data and listing_data.get("title"):
                                   listings.append(listing_data)
                                   
                           except Exception as e:
                               self.logger.warning(f"Error processing listing {i}: {e}")
                               continue
                       
                       break  # Found listings with this selector
                       
               except NoSuchElementException:
                   continue
           
           self.logger.info(f"Successfully extracted {len(listings)} listings")
           return listings
           
       except Exception as e:
           self.logger.error(f"Error scraping listings: {e}")
           return []
   
   def handle_pagination(self, max_pages: int = 5) -> List[Dict]:
       """Handle pagination and scrape multiple pages"""
       all_listings = []
       current_page = 1
       
       while current_page <= max_pages:
           try:
               self.logger.info(f"Scraping page {current_page}")
               
               # Scrape current page
               page_listings = self.scrape_listings()
               all_listings.extend(page_listings)
               
               if not page_listings:
                   self.logger.warning(f"No listings found on page {current_page}")
                   break
               
               # Try to find next page button
               next_button_selectors = [
                   ".searchResultsButton.next",
                   ".pagination-next",
                   "[data-testid='next-page']",
                   "a[aria-label='Next']"
               ]
               
               next_button = None
               for selector in next_button_selectors:
                   try:
                       next_button = self.driver.find_element(By.CSS_SELECTOR, selector)
                       if next_button and next_button.is_enabled():
                           break
                   except NoSuchElementException:
                       continue
               
               if not next_button or not next_button.is_enabled():
                   self.logger.info("No more pages available")
                   break
               
               # Click next page with human behavior
               self.human_behavior.simulate_mouse_movement()
               self.human_behavior.human_delay(1, 3)
               
               self.driver.execute_script("arguments[0].click();", next_button)
               
               # Wait for new page to load
               self.human_behavior.human_delay(3, 6)
               
               # Check if we're still on a valid page
               if not self.wait_for_listings_table():
                   self.logger.error("Failed to load next page")
                   break
               
               current_page += 1
               
           except Exception as e:
               self.logger.error(f"Error handling pagination on page {current_page}: {e}")
               break
       
       return all_listings
   
   def save_data(self, data: List[Dict]) -> None:
       """Save scraped data to JSON file"""
       try:
           output_file = Path(self.config.OUTPUT_FILE)
           
           with open(output_file, 'w', encoding='utf-8') as f:
               json.dump(data, f, indent=2, ensure_ascii=False)
           
           self.logger.info(f"Data saved to {output_file}")
           self.logger.info(f"Total listings saved: {len(data)}")
           
       except Exception as e:
           self.logger.error(f"Error saving data: {e}")
   
   def run(self, max_pages: int = 5) -> bool:
       """Main scraping workflow"""
       try:
           self.logger.info("Starting advanced Sahibinden scraper...")
           
           # Initialize driver
           if not self.initialize_driver():
               self.logger.error("Failed to initialize driver")
               return False
           
           # Navigate to target
           if not self.navigate_to_target():
               self.logger.error("Failed to navigate to target")
               return False
           
           # Scrape listings
           all_listings = self.handle_pagination(max_pages)
           
           if not all_listings:
               self.logger.error("No listings found")
               return False
           
           # Save data
           self.save_data(all_listings)
           
           self.logger.info("Scraping completed successfully!")
           return True
           
       except Exception as e:
           self.logger.error(f"Fatal error during scraping: {e}")
           return False
           
       finally:
           self.cleanup()
   
   def cleanup(self) -> None:
       """Clean up resources"""
       try:
           if self.flaresolverr:
               self.flaresolverr.destroy_session()
           
           if self.driver:
               self.logger.info("Keeping browser open for manual inspection...")
               # Don't quit the driver to allow manual inspection
               # self.driver.quit()
               
       except Exception as e:
           self.logger.error(f"Error during cleanup: {e}")

# =============================================================================
# MAIN EXECUTION
# =============================================================================

def main():
   """Main execution function"""
   config = Config()
   
   # Display configuration
   print("="*80)
   print("ADVANCED SAHIBINDEN SCRAPER - PRODUCTION GRADE")
   print("="*80)
   print(f"Target URL: {config.TARGET_URL}")
   print(f"Chrome Profile: {config.CHROME_PROFILE_DIR}")
   print(f"Proxy Enabled: {config.PROXY_ENABLED}")
   print(f"CAPTCHA Solver: {config.CAPTCHA_SERVICE if config.CAPTCHA_ENABLED else 'Disabled'}")
   print(f"FlareSolverr: {'Enabled' if config.FLARESOLVERR_ENABLED else 'Disabled'}")
   print("="*80)
   
   # Create and run scraper
   scraper = AdvancedSahibindenScraper(config)
   
   try:
       success = scraper.run(max_pages=3)  # Scrape first 3 pages
       
       if success:
           print("\n" + "="*80)
           print("SCRAPING COMPLETED SUCCESSFULLY!")
           print("="*80)
           print(f"Check {config.OUTPUT_FILE} for results")
       else:
           print("\n" + "="*80)
           print("SCRAPING FAILED!")
           print("="*80)
           print("Check the logs for more details")
           
   except KeyboardInterrupt:
       print("\n" + "="*80)
       print("SCRAPING INTERRUPTED BY USER")
       print("="*80)
       scraper.cleanup()
       
   except Exception as e:
       print(f"\n" + "="*80)
       print(f"UNEXPECTED ERROR: {e}")
       print("="*80)
       scraper.cleanup()

if __name__ == "__main__":
   main()
